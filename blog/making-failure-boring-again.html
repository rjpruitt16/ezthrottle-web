<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>EZThrottle: Making Failure Boring Again - EZThrottle Blog</title>
    <meta name="description" content="Modern software fails with 429s, timeouts, and regions going dark. EZThrottle turns retries, rate limits, and region health into shared state.">
    <meta name="author" content="Rahmi Pruitt">

    <!-- Open Graph / Social -->
    <meta property="og:title" content="EZThrottle: Making Failure Boring Again">
    <meta property="og:description" content="Modern software fails with 429s, timeouts, and regions going dark. EZThrottle turns retries into shared state.">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://ezthrottle.network/blog/making-failure-boring-again">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:creator" content="@RahmiPruitt">

    <script src="https://cdn.tailwindcss.com"></script>
</head>
<body class="bg-gray-50">
    <!-- Navigation -->
    <div class="bg-white border-b">
        <div class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-4">
            <div class="flex justify-between items-center">
                <a href="/" class="text-2xl font-bold text-gray-900">EZThrottle</a>
                <div class="space-x-6 text-sm">
                    <a href="/blog" class="text-gray-600 hover:text-black">Blog</a>
                    <a href="/faq" class="text-gray-600 hover:text-black">FAQ</a>
                    <a href="https://github.com/rjpruitt16/ezthrottle-web" target="_blank" class="text-gray-600 hover:text-black">GitHub</a>
                    <a href="/login" class="text-gray-600 hover:text-black">Login</a>
                    <a href="/signup" class="bg-black text-white px-4 py-2 rounded hover:bg-gray-800">Sign Up</a>
                </div>
            </div>
        </div>
    </div>

    <!-- Article -->
    <article class="max-w-3xl mx-auto px-4 sm:px-6 lg:px-8 py-16">
        <!-- Header -->
        <header class="mb-12">
            <p class="text-sm text-gray-500 mb-2">
                <a href="/blog" class="hover:text-black">&larr; Back to Blog</a>
            </p>
            <h1 class="text-4xl font-bold text-gray-900 mb-4">
                EZThrottle: Making Failure Boring Again
            </h1>
            <div class="flex items-center text-sm text-gray-500">
                <span>By <a href="https://twitter.com/RahmiPruitt" target="_blank" class="text-blue-600 hover:underline">@RahmiPruitt</a></span>
                <span class="mx-2">&middot;</span>
                <time datetime="2026-01-28">January 28, 2026</time>
            </div>
        </header>

        <!-- Content -->
        <div class="prose prose-lg max-w-none">
            <div class="bg-red-50 border-l-4 border-red-500 p-6 mb-8">
                <p class="text-gray-900 font-medium mb-4">
                    You're getting paged at 2am because your retry logic just turned a rate limit into a cascading outage.
                </p>
                <p class="text-gray-700 mb-4">
                    1000 workers. All hit OpenAI's rate limit. All retrying independently.
                </p>
                <p class="text-gray-700 mb-2"><strong>What this costs you:</strong></p>
                <ul class="list-disc pl-6 text-gray-700 space-y-1">
                    <li>Workers run 10x longer (retrying instead of processing)</li>
                    <li>Workflows fail mid-execution (restart from scratch)</li>
                    <li>Tomorrow's bill: <strong>$15k</strong> in wasted compute + API calls</li>
                </ul>
                <p class="text-gray-700 mt-4 font-medium">
                    Every. Single. Day.
                </p>
            </div>

            <p class="text-xl text-gray-900 font-semibold mb-8">
                This is normal. And it shouldn't be.
            </p>

            <p class="text-gray-700 mb-8">
                I built EZThrottle because I got tired of pretending this was acceptable.
            </p>

            <h2 class="text-2xl font-bold text-gray-900 mt-12 mb-4">The Problem Nobody Really Talks About</h2>

            <p class="text-gray-700 mb-4">
                Most systems deal with failure in isolation. Each service:
            </p>
            <ul class="list-disc pl-6 mb-6 text-gray-700 space-y-2">
                <li>sends a request</li>
                <li>gets a 429 or timeout</li>
                <li>retries on its own schedule</li>
                <li>hopes for the best</li>
            </ul>

            <p class="text-gray-700 mb-4">
                This works... until it doesn't.
            </p>
            <p class="text-gray-700 mb-4">
                At scale, independent retries turn into retry storms:
            </p>
            <ul class="list-disc pl-6 mb-6 text-gray-700 space-y-2">
                <li>rate limits get hammered</li>
                <li>upstreams get slower</li>
                <li>outages cascade</li>
                <li>tail latency explodes</li>
            </ul>

            <p class="text-gray-700 mb-4">
                The real issue isn't that APIs fail. It's that every client is blind to what every other client is experiencing.
            </p>

            <p class="text-xl font-semibold text-gray-900 mb-6">
                Failure isn't shared state.
            </p>

            <h2 class="text-2xl font-bold text-gray-900 mt-12 mb-4">"Why Not Just Use Exponential Backoff?"</h2>

            <p class="text-gray-700 mb-4">
                This is the first question everyone asks. And it's a good one.
            </p>
            <p class="text-gray-700 mb-4">
                Exponential backoff works beautifully when you have <strong>one client</strong> talking to <strong>one server</strong>.
                Hit a rate limit, wait longer, try again. Problem solved.
            </p>
            <p class="text-gray-700 mb-4">
                Now picture N clients hitting the same API.
            </p>
            <p class="text-gray-700 mb-4">
                They all hit the rate limit at roughly the same time. They all start backing off independently.
                They all retry after the backoff window... at roughly the same time. The thundering herd.
            </p>
            <p class="text-gray-700 mb-4">
                Here's the math:
            </p>
            <ul class="list-disc pl-6 mb-6 text-gray-700 space-y-2">
                <li><strong>N clients</strong> each discover the rate limit independently</li>
                <li>Each client retries 3 times = <strong>3N wasted requests</strong></li>
                <li>The upstream sees 3N retry storms instead of controlled traffic</li>
                <li>Your CPU spends cycles sleeping and retrying instead of handling real work</li>
            </ul>
            <p class="text-gray-700 mb-4">
                EZThrottle sees the same rate limit <strong>once</strong>.
                One client discovers it, the shared state updates, and everyone slows down together.
            </p>
            <p class="text-xl font-semibold text-gray-900 mb-8">
                N clients × 3 retries = 3N wasted requests.<br>
                EZThrottle: ~1.
            </p>

            <h2 class="text-2xl font-bold text-gray-900 mt-12 mb-4">The DIY Retry Queue: A Horror Story</h2>

            <p class="text-gray-700 mb-4">
                "What if we just build a retry queue ourselves?"
            </p>
            <p class="text-gray-700 mb-4">
                Let me tell you how this goes. I've seen it. I've lived it.
            </p>
            <p class="text-gray-700 mb-6">
                <strong>Month 1:</strong> You have N clients fighting for quota Q on a single API.
                Retry storms are killing you. Someone suggests a centralized queue.<br>
                <span class="text-red-600 font-medium">Cost: $15k/month in wasted compute (workers retrying instead of working)</span>
            </p>
            <p class="text-gray-700 mb-6">
                <strong>Month 2:</strong> You build the queue. It works! Requests flow through one bottleneck,
                rate limiting is enforced, retries are controlled. Ship it. Victory beer.<br>
                <span class="text-green-600 font-medium">Cost drops to $3k/month. But now you're paying $2k/month for SQS.</span>
            </p>
            <p class="text-gray-700 mb-6">
                <strong>Month 3:</strong> You add more URLs. Five APIs. Ten APIs. Twenty.
                One queue. Twenty different rate limits. Some APIs allow 100 RPS, some allow 2.
                The fast ones starve behind the slow ones. Everything is unbearable.<br>
                <span class="text-red-600 font-medium">Latency: 5 seconds per request (was 200ms). Customers complaining.</span>
            </p>
            <p class="text-gray-700 mb-6">
                <strong>Month 6:</strong> "We need queue-per-URL." You spin up a fleet of workers.
                Each URL gets its own queue with its own rate limit. The architecture diagram now
                requires a team to maintain.<br>
                <span class="text-red-600 font-medium">Cost: $8k/month infra + 1 DevOps engineer ($150k/year)</span>
            </p>
            <p class="text-gray-700 mb-6">
                <strong>Month 9:</strong> The CTO signs a 10x contract. Traffic explodes.
                Your queue-per-URL workers can't keep up. The single-server architecture
                doesn't scale. You miss your son's birthday debugging Redis connection pools.<br>
                <span class="text-red-600 font-medium">Cost: $25k/month infra + 2 more engineers ($300k/year)</span>
            </p>
            <p class="text-gray-700 mb-6">
                <strong>Month 12:</strong> You cancel your vacation. Again.
                The team implements Zookeeper for coordination, Redis for state,
                and Kubernetes for orchestration. Six months of infrastructure work
                to solve a problem that has nothing to do with your actual product.<br>
                <span class="text-red-600 font-medium">Cost: $50k/month infra + team of 3 engineers ($500k/year)</span>
            </p>

            <div class="bg-red-50 border-l-4 border-red-500 p-4 my-6">
                <p class="text-gray-900">
                    Serverless should be painless and opsless&mdash;not managing a fucking factory of queues.
                </p>
            </div>

            <p class="text-gray-700 mb-6">
                <strong>Month 14:</strong> The CTO heard about this thing called EZThrottle.
                "Can we go global? Multi-region?" You stare at your Zookeeper cluster.
                Managed Redis alone is $1,000/month. Just for the storage layer.
                You think about your original job description. You update your LinkedIn.
            </p>

            <div class="bg-green-50 border-l-4 border-green-500 p-4 my-6">
                <p class="text-gray-900 font-medium mb-2">Or with EZThrottle:</p>
                <p class="text-gray-700">$50-500/month. Zero infrastructure. Multi-region included. Ship in an afternoon.</p>
            </div>

            <pre class="bg-gray-900 text-gray-100 p-4 rounded-lg overflow-x-auto mb-8 text-sm"><code>pip install ezthrottle</code></pre>

            <h2 class="text-2xl font-bold text-gray-900 mt-12 mb-4">Why This Is Natural for the BEAM</h2>

            <p class="text-gray-700 mb-4">
                Here's the thing: queue-per-URL is a nightmare in most languages.
            </p>
            <p class="text-gray-700 mb-4">
                In the BEAM? It's the obvious design.
            </p>
            <p class="text-gray-700 mb-4">
                Erlang was built for telephone switches. A phone switch doesn't have "one queue for all calls."
                It has a process per call. A process per connection. A process per subscriber.
                The actor model makes this trivial&mdash;spawn a process, it handles its own state,
                it fails in isolation without taking down its neighbors.
            </p>
            <p class="text-gray-700 mb-4">
                EZThrottle does the same thing for URLs. Each destination gets its own process.
                Its own rate limit tracking. Its own retry state. Millions of them, running concurrently,
                coordinating through message passing instead of shared memory locks.
            </p>
            <p class="text-gray-700 mb-4">
                And because EZThrottle runs on Fly.io, forwarding a request to another region
                is just an API call. The Fly proxy handles the hard parts&mdash;anycast routing,
                WireGuard tunnels between regions, health checking.
            </p>
            <p class="text-gray-700 mb-8">
                What takes six months of Zookeeper and Redis in other stacks
                is a weekend of Gleam code on the BEAM.
            </p>

            <!-- Image 1: The problem -->
            <figure class="my-8">
                <img src="/blog/images/failure-without-coordination.png" alt="Multiple services independently hitting a single upstream API" class="w-full rounded-lg shadow-lg">
                <figcaption class="text-sm text-gray-500 mt-2 text-center">Without coordination, every service independently hammers the same upstream</figcaption>
            </figure>

            <h2 class="text-2xl font-bold text-gray-900 mt-12 mb-4">The Simple Idea That Changed Everything</h2>

            <p class="text-gray-700 mb-4">
                EZThrottle is built around one opinionated idea:
            </p>
            <p class="text-xl font-semibold text-gray-900 mb-6">
                Retries shouldn't be independent.
            </p>

            <p class="text-gray-700 mb-4">
                Instead of thousands of machines panicking at once, EZThrottle coordinates failure in one place.
            </p>
            <p class="text-gray-700 mb-4">
                All outbound requests flow through EZThrottle, which keeps track of:
            </p>
            <ul class="list-disc pl-6 mb-6 text-gray-700 space-y-2">
                <li>how fast a destination can actually handle traffic</li>
                <li>which regions are healthy</li>
                <li>when it's time to slow down or reroute</li>
            </ul>

            <p class="text-xl font-semibold text-gray-900 mb-8">
                Once failure becomes shared state, it stops being chaos.
            </p>

            <h2 class="text-2xl font-bold text-gray-900 mt-12 mb-4">Why This Runs on the BEAM (and Why That Matters)</h2>

            <p class="text-gray-700 mb-4">
                EZThrottle is written in Gleam and runs on Erlang/OTP.
            </p>
            <p class="text-gray-700 mb-4">
                That choice wasn't about trends&mdash;it was about survival.
            </p>
            <p class="text-gray-700 mb-4">The BEAM was designed for:</p>
            <ul class="list-disc pl-6 mb-6 text-gray-700 space-y-2">
                <li>massive concurrency</li>
                <li>message passing instead of shared memory</li>
                <li>processes that fail without taking everything else down</li>
                <li>distributed coordination that doesn't fall apart under load</li>
            </ul>

            <p class="text-gray-700 mb-4">
                EZThrottle isn't trying to make one HTTP call fast. It's trying to coordinate millions of them safely. This is exactly what the BEAM is good at.
            </p>

            <p class="text-gray-700 mb-8">
                This isn't theoretical. BEAM powers telephone switches that handle millions of calls
                with 99.9999999% uptime — nine nines. When "down" means emergency calls don't connect,
                you build different. EZThrottle inherits that DNA.
            </p>

            <h2 class="text-2xl font-bold text-gray-900 mt-12 mb-4">429s Aren't Errors &mdash; They're Signals</h2>

            <p class="text-gray-700 mb-4">
                A 429 isn't your API yelling at you. It's your API asking you to slow down.
            </p>
            <p class="text-gray-700 mb-6">
                Most systems ignore that signal and keep retrying anyway.
            </p>
            <p class="text-gray-700 mb-6">
                EZThrottle takes the hint.
            </p>

            <h3 class="text-xl font-bold text-gray-900 mt-8 mb-4">The boring default (on purpose)</h3>

            <p class="text-gray-700 mb-4">
                By default, EZThrottle sends 2 requests per second per target domain.
            </p>
            <p class="text-gray-700 mb-4">
                Not globally. Not per account. <strong>Per destination.</strong>
            </p>
            <p class="text-gray-700 mb-4">Examples:</p>
            <ul class="list-disc pl-6 mb-6 text-gray-700 space-y-2">
                <li><code class="bg-gray-100 px-2 py-1 rounded">api.stripe.com</code> &rarr; 2 RPS</li>
                <li><code class="bg-gray-100 px-2 py-1 rounded">api.openai.com</code> &rarr; 2 RPS</li>
                <li><code class="bg-gray-100 px-2 py-1 rounded">api.anthropic.com</code> &rarr; 2 RPS</li>
            </ul>

            <p class="text-gray-700 mb-4">
                This default exists to prevent your infrastructure from accidentally turning into a distributed denial-of-service attack.
            </p>
            <p class="text-gray-700 mb-6">
                It smooths bursts, stops retry storms, and keeps upstreams healthy.
            </p>
            <p class="text-gray-700 mb-4">
                Yes, it's conservative. That's the point.
            </p>

            <p class="text-gray-700 mb-8">
                The real insight: you can tune traffic with a <strong>header change</strong> instead
                of deploying new servers. Traditional scaling means spinning up infrastructure, updating configs, waiting for DNS.
                EZThrottle scaling is a code change. Your ops team will thank you.
            </p>

            <h2 class="text-2xl font-bold text-gray-900 mt-12 mb-4">How Rate Limits Work</h2>

            <p class="text-gray-700 mb-4">
                EZThrottle enforces rate limits automatically. Clients don't control the rate &mdash; the service maintainer does.
            </p>
            <p class="text-gray-700 mb-4">
                If you're building an API and want to tell EZThrottle how fast you can handle traffic, respond with these headers:
            </p>
            <pre class="bg-gray-100 text-gray-800 p-4 rounded-lg overflow-x-auto mb-6 text-sm"><code>X-EZTHROTTLE-RPS: 5
X-EZTHROTTLE-MAX-CONCURRENT: 10</code></pre>

            <p class="text-gray-700 mb-4">
                EZThrottle reads these and adjusts. No client configuration needed &mdash; rate limiting happens at the infrastructure layer.
            </p>
            <p class="text-gray-700 mb-4">
                The important part isn't the knobs. It's this:
            </p>
            <p class="text-xl font-semibold text-gray-900 mb-8">
                Rate limiting becomes shared state instead of a thousand <code class="bg-gray-100 px-2 py-1 rounded">sleep()</code> calls.
            </p>

            <h2 class="text-2xl font-bold text-gray-900 mt-12 mb-4">When Things Actually Break (5xx and Outages)</h2>

            <p class="text-gray-700 mb-4">
                Regions go down. Configs break. Dependencies flake out.
            </p>
            <p class="text-gray-700 mb-4">
                EZThrottle assumes this will happen.
            </p>
            <p class="text-gray-700 mb-4">
                When a request fails with a 5xx or times out:
            </p>
            <ul class="list-disc pl-6 mb-6 text-gray-700 space-y-2">
                <li>that region is marked as unhealthy</li>
                <li>traffic is rerouted to healthy regions</li>
                <li>optionally, requests are raced across regions</li>
            </ul>

            <p class="text-gray-700 mb-4">The result isn't "everything is perfect."</p>
            <p class="text-gray-700 mb-6">The result is: <strong>a small latency bump instead of a full outage.</strong></p>

            <div class="bg-blue-50 border-l-4 border-blue-500 p-4 my-6">
                <p class="font-semibold text-gray-900 mb-2">Bidirectional protection:</p>
                <p class="text-gray-700 text-sm">
                    Your customers are protected from YOUR outages — if your region goes down, requests route elsewhere.
                    And you're protected from your API providers having outages — requests distribute across healthy regions.
                    A load balancer can't do this. It just distributes traffic to your servers. EZThrottle coordinates across regions and providers.
                </p>
            </div>

            <!-- Image 2: The solution -->
            <figure class="my-8">
                <img src="/blog/images/ezthrottle-architecture.png" alt="EZThrottle coordinating requests across multiple regions" class="w-full rounded-lg shadow-lg">
                <figcaption class="text-sm text-gray-500 mt-2 text-center">EZThrottle coordinates traffic across regions with consensus and controlled rate limiting</figcaption>
            </figure>

            <h2 class="text-2xl font-bold text-gray-900 mt-12 mb-4">Region Racing: Let the Fastest One Win</h2>

            <p class="text-gray-700 mb-4">
                Sometimes you don't want to wait. You just want the request to finish.
            </p>
            <p class="text-gray-700 mb-4">EZThrottle supports region racing:</p>
            <ul class="list-disc pl-6 mb-6 text-gray-700 space-y-2">
                <li>send the same request to multiple regions</li>
                <li>accept the first success</li>
                <li>cancel the rest</li>
            </ul>

            <p class="text-gray-700 mb-4">Here's what that looks like:</p>
            <pre class="bg-gray-900 text-gray-100 p-4 rounded-lg overflow-x-auto mb-6 text-sm"><code>from ezthrottle import EZThrottle, Step, StepType

client = EZThrottle(api_key="your_api_key")

result = (
    Step(client)
    .url("https://api.example.com/endpoint")
    .method("POST")
    .type(StepType.PERFORMANCE)
    .regions(["iad", "lax", "ord"])
    .execution_mode("race")
    .webhooks([{"url": "https://your-app.com/webhook"}])
    .execute()
)</code></pre>

            <p class="text-gray-700 mb-8">
                This isn't about chasing microbenchmarks. It's about <strong>predictable completion when the world is messy.</strong>
            </p>

            <h2 class="text-2xl font-bold text-gray-900 mt-12 mb-4">Two Ways to Use EZThrottle</h2>

            <p class="text-gray-700 mb-6">
                Not every request needs the same level of reliability. That's why EZThrottle supports two modes:
            </p>

            <!-- PERFORMANCE Mode -->
            <div class="bg-blue-50 border-l-4 border-blue-500 p-6 mb-6">
                <h3 class="font-bold text-blue-900 text-lg mb-2">PERFORMANCE Mode</h3>
                <p class="text-blue-800 mb-3">Always route through EZThrottle. Every request gets multi-region racing, automatic retries, and webhook delivery.</p>
                <p class="text-blue-700 text-sm"><strong>Use when:</strong> Reliability &gt; cost. Payment processing, critical notifications, anything where failure means lost revenue.</p>
            </div>

            <pre class="bg-gray-900 text-gray-100 p-4 rounded-lg overflow-x-auto mb-6 text-sm"><code>result = (
    Step(client)
    .url("https://api.stripe.com/charges")
    .type(StepType.PERFORMANCE)
    .regions(["iad", "lax", "ord"])
    .execution_mode("race")
    .webhooks([{"url": "https://your-app.com/webhook"}])
    .execute()
)</code></pre>

            <!-- FRUGAL Mode -->
            <div class="bg-green-50 border-l-4 border-green-500 p-6 mb-6">
                <h3 class="font-bold text-green-900 text-lg mb-2">FRUGAL Mode</h3>
                <p class="text-green-800 mb-3">Execute locally first. Only forward to EZThrottle when you hit rate limits or errors. Pay nothing when things work.</p>
                <p class="text-green-700 text-sm"><strong>Use when:</strong> Cost &gt; reliability. Analytics, logging, non-critical APIs with 95%+ success rates.</p>
            </div>

            <pre class="bg-gray-900 text-gray-100 p-4 rounded-lg overflow-x-auto mb-6 text-sm"><code>result = (
    Step(client)
    .url("https://api.example.com/endpoint")
    .type(StepType.FRUGAL)
    .fallback_on_error([429, 500, 502, 503])
    .webhooks([{"url": "https://your-app.com/webhook"}])
    .execute()
)</code></pre>

            <p class="text-gray-700 mb-8">
                Most teams start with FRUGAL for non-critical paths, then flip to PERFORMANCE for anything that wakes them up at night.
            </p>

            <h2 class="text-2xl font-bold text-gray-900 mt-12 mb-4">The Tradeoff EZThrottle Makes (On Purpose)</h2>

            <p class="text-gray-700 mb-4">EZThrottle prioritizes:</p>
            <ul class="list-disc pl-6 mb-6 text-gray-700 space-y-2">
                <li>predictable completion</li>
                <li>bounded failure</li>
                <li>coordinated recovery</li>
            </ul>

            <p class="text-gray-700 mb-4">Over:</p>
            <ul class="list-disc pl-6 mb-6 text-gray-700 space-y-2">
                <li>maximum burst throughput</li>
                <li>raw, unbounded speed</li>
            </ul>

            <p class="text-gray-700 mb-8">
                If you want every request to fire as fast as possible, EZThrottle isn't for you.<br>
                If you want to stop waking up to retry storms, it probably is.
            </p>

            <h2 class="text-2xl font-bold text-gray-900 mt-12 mb-4">"But Isn't This a Single Point of Failure?"</h2>

            <p class="text-gray-700 mb-4">
                This is the second question everyone asks. It's a fair concern.
            </p>
            <p class="text-gray-700 mb-4">
                But here's the thing: EZThrottle isn't a dependency. It's a <strong>reliability layer</strong>.
            </p>
            <p class="text-gray-700 mb-4">
                Every SDK ships with <code class="bg-gray-100 px-2 py-1 rounded">forward_or_fallback()</code>.
                If EZThrottle is unreachable, you fall back to whatever you were doing before:
            </p>

            <pre class="bg-gray-900 text-gray-100 p-4 rounded-lg overflow-x-auto mb-6 text-sm"><code>from ezthrottle import EZThrottle
import requests

client = EZThrottle(api_key="your_api_key")

# If EZThrottle is down, fall back to direct HTTP call
result = client.forward_or_fallback(
    fallback=lambda: requests.post(
        "https://api.stripe.com/charges",
        headers={"Authorization": "Bearer sk_live_..."},
        json={"amount": 1000}
    ),
    url="https://api.stripe.com/charges",
    method="POST",
    headers={"Authorization": "Bearer sk_live_..."},
    body='{"amount": 1000}'
)</code></pre>

            <p class="text-gray-700 mb-4">
                If EZThrottle goes down:
            </p>
            <ul class="list-disc pl-6 mb-6 text-gray-700 space-y-2">
                <li>Your requests still go through (via fallback)</li>
                <li>You lose the coordination features temporarily</li>
                <li>You're back to independent retries until EZThrottle recovers</li>
            </ul>

            <p class="text-gray-700 mb-4">
                That's the worst case: you're back to where you started.
            </p>
            <p class="text-xl font-semibold text-gray-900 mb-8">
                EZThrottle failing doesn't break your system. It just means you lose the extra reliability&mdash;temporarily.
            </p>

            <h2 class="text-2xl font-bold text-gray-900 mt-12 mb-4">What EZThrottle Is (and Isn't)</h2>

            <p class="text-gray-700 mb-4"><strong>EZThrottle is:</strong></p>
            <ul class="list-disc pl-6 mb-6 text-gray-700 space-y-2">
                <li>a reliable HTTP transport</li>
                <li>a coordination layer for outbound requests</li>
                <li>a way to make failure boring again</li>
            </ul>

            <p class="text-gray-700 mb-4"><strong>EZThrottle is not:</strong></p>
            <ul class="list-disc pl-6 mb-6 text-gray-700 space-y-2">
                <li>a database</li>
                <li>a general compute platform</li>
                <li>a replacement for business logic</li>
            </ul>

            <p class="text-gray-700 mb-8">
                Requests live in memory, move through the system, and disappear. There's nothing to mine, leak, or hoard.
            </p>

            <h2 class="text-2xl font-bold text-gray-900 mt-12 mb-4">Who Needs This?</h2>

            <p class="text-gray-700 mb-4"><strong>You probably need EZThrottle if:</strong></p>
            <ul class="list-disc pl-6 mb-6 text-gray-700 space-y-2">
                <li>You're making &gt;1M API calls/month to external services</li>
                <li>You have &gt;50 workers/instances calling the same APIs</li>
                <li>You've been rate limited and it cascaded into an outage</li>
                <li>You're managing queues just to handle retries</li>
                <li>You're calling AI APIs (OpenAI, Anthropic, etc.) at scale</li>
                <li>You're building AI agents that make dozens of API calls per workflow</li>
            </ul>

            <p class="text-gray-700 mb-4"><strong>You probably don't need this if:</strong></p>
            <ul class="list-disc pl-6 mb-8 text-gray-700 space-y-2">
                <li>Single server making occasional API calls</li>
                <li>&lt;10k requests/month</li>
                <li>You only call APIs you control (not external rate limits)</li>
                <li>Exponential backoff is genuinely working fine for you</li>
            </ul>

            <h2 class="text-2xl font-bold text-gray-900 mt-12 mb-4">Why This Matters</h2>

            <p class="text-gray-700 mb-4">
                Most infrastructure complexity exists to compensate for unreliable networks.
            </p>
            <p class="text-gray-700 mb-4">
                EZThrottle doesn't eliminate failure.
            </p>
            <p class="text-xl font-semibold text-gray-900 mb-6">
                It eliminates panic.
            </p>

            <p class="text-gray-700 mb-8">
                By turning retries, rate limits, and region health into shared state, it gives you something rare in distributed systems:
            </p>
            <p class="text-2xl font-bold text-gray-900 mb-12">
                Predictable behavior when things go wrong.
            </p>

            <!-- Next Article -->
            <div class="bg-gradient-to-r from-blue-50 to-purple-50 border border-blue-200 rounded-lg p-6 mt-12">
                <p class="text-gray-700 mb-4">
                    But making failure boring isn't enough. Engineers need to ship features, not fight infrastructure.
                    The real question is: <strong>what can you build when Layer 7 is reliable?</strong>
                </p>
                <p class="text-gray-700 mb-4">
                    Fallback racing across providers. Webhook fanout with quorum. Workflows that replace Step Functions.
                    Legacy code wrappers that onboard in minutes. Event-driven architecture without SQS.
                </p>
                <a href="/blog/serverless-2-rip-operations" class="inline-flex items-center text-blue-600 font-semibold hover:underline">
                    Continue reading: Serverless 2.0 &mdash; RIP Operations &rarr;
                </a>
            </div>
        </div>

        <!-- SDKs -->
        <div class="border-t pt-8 mt-12">
            <h3 class="text-xl font-bold text-gray-900 mb-4">Get Started</h3>
            <p class="text-gray-700 mb-4">SDKs available for:</p>
            <div class="flex flex-wrap gap-4">
                <a href="https://github.com/rjpruitt16/ezthrottle-python" target="_blank" class="inline-flex items-center px-4 py-2 bg-gray-100 rounded-lg hover:bg-gray-200 text-gray-800 font-medium">
                    Python
                </a>
                <a href="https://github.com/rjpruitt16/ezthrottle-node" target="_blank" class="inline-flex items-center px-4 py-2 bg-gray-100 rounded-lg hover:bg-gray-200 text-gray-800 font-medium">
                    Node.js
                </a>
                <a href="https://github.com/rjpruitt16/ezthrottle-go" target="_blank" class="inline-flex items-center px-4 py-2 bg-gray-100 rounded-lg hover:bg-gray-200 text-gray-800 font-medium">
                    Go
                </a>
            </div>
        </div>

        <!-- Author -->
        <div class="border-t pt-8 mt-12">
            <div class="flex items-center">
                <div>
                    <p class="font-semibold text-gray-900">Rahmi Pruitt</p>
                    <p class="text-sm text-gray-600">Founder, EZThrottle</p>
                    <a href="https://twitter.com/RahmiPruitt" target="_blank" class="text-sm text-blue-600 hover:underline">@RahmiPruitt</a>
                </div>
            </div>
        </div>
    </article>

    <!-- CTA -->
    <div class="bg-black text-white py-16">
        <div class="max-w-4xl mx-auto px-4 text-center">
            <h2 class="text-3xl font-bold mb-4">Ready to Make Failure Boring?</h2>
            <p class="text-xl mb-8">Start with 1 million free requests. No credit card required.</p>
            <a href="/signup"
               class="inline-block bg-white text-black px-8 py-3 rounded-lg font-semibold hover:bg-gray-100">
                Start Free &rarr;
            </a>
        </div>
    </div>

    <!-- Footer -->
    <div class="border-t py-8 bg-gray-50">
        <div class="max-w-7xl mx-auto px-4 text-center text-gray-600">
            <p class="font-semibold text-gray-900">&copy; 2026 EZThrottle. TCP for APIs. The World's First API Aqueduct&trade;</p>
            <p class="text-sm mt-2">Built on BEAM by a solo founder who believes engineers deserve to sleep at night.</p>
            <div class="mt-4 space-x-4">
                <a href="/" class="hover:text-black">Home</a>
                <a href="/blog" class="hover:text-black">Blog</a>
                <a href="/faq" class="hover:text-black">FAQ</a>
                <a href="https://github.com/rjpruitt16/ezthrottle-web" target="_blank" class="hover:text-black">GitHub</a>
                <a href="https://github.com/rjpruitt16/ezthrottle-sdks" target="_blank" class="hover:text-black">SDKs</a>
                <a href="https://twitter.com/RahmiPruitt" target="_blank" class="hover:text-black">Twitter</a>
                <a href="https://www.linkedin.com/in/rahmi-pruitt-a1bb4a127/" target="_blank" class="hover:text-black">LinkedIn</a>
                <a href="https://www.youtube.com/@theblacktechexperience" target="_blank" class="hover:text-black">YouTube</a>
                <a href="mailto:support@ezthrottle.network" class="hover:text-black">Contact</a>
            </div>
        </div>
    </div>
</body>
</html>
